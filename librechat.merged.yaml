# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# File strategy s3/firebase
# fileStrategy: "s3"

# Custom interface configuration
interface:
  customWelcome: "Welkom bij GovAI!"
  # Privacy policy settings
  # privacyPolicy:
  #   externalUrl: 'https://gradient-ds.com/'
  #   openNewTab: true

  # Terms of service
  termsOfService:
    # externalUrl: 'https://gradient-ds.com/'
    openNewTab: true
    modalAcceptance: true
    modalTitle: "Gebruiksvoorwaarden voor GovAI (Demo)"
    modalContent: |
      ### GovAI Demo – Fair use & geen vertrouwelijke data

      Deze demo wordt “as is” aangeboden, alleen voor evaluatiedoeleinden. We kunnen de demo op elk moment wijzigen of intrekken.

      Door door te gaan, ga je akkoord met het volgende:
      - Gebruik de dienst eerlijk en rechtmatig (fair use).
      - **Upload géén vertrouwelijke, persoonlijke of gevoelige gegevens** (geen PII, bedrijfsgeheimen of vertrouwelijke documenten).
      - Uitvoer kan onjuist zijn; gebruik niet voor kritieke besluiten.
      - Geen garanties of aansprakelijkheid.

      Wil je echte/sensitieve data verwerken? Neem contact op voor een productieaccount.

      Door de demo te gebruiken, accepteer je deze voorwaarden.
  endpointsMenu: true
  modelSelect: true
  parameters: false
  sidePanel: true
  presets: false
  prompts: true
  bookmarks: true
  multiConvo: false
  agents: true
  fileCitations: true
  memories: false
  fileSearch: true
  webSearch: true
  marketplace: 
    use: false
  # Temporary chat retention period in hours (default: 720, min: 1, max: 8760)
  # temporaryChatRetention: 1

# Example Cloudflare turnstile (optional)
#turnstile:
#  siteKey: "your-site-key-here"
#  options:
#    language: "auto"    # "auto" or an ISO 639-1 language code (e.g. en)
#    size: "normal"      # Options: "normal", "compact", "flexible", or "invisible"

# Example Registration Object Structure (optional)
registration:
#   socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']
  allowedDomains:
    - "gradient-ds.com"


# Example Balance settings
balance:
  enabled: true
  startBalance: 500000
  autoRefillEnabled: true
  refillIntervalValue: 1
  refillIntervalUnit: 'days'
  refillAmount: 100000

# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']

#
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

# rateLimits:
#   fileUploads:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

# Example Actions Object Structure
# actions:
#   allowedDomains:
#     - "swapi.dev"
#     - "librechat.ai"
#     - "google.com"

fileConfig:
  endpoints:
    agents:
      disabled: false
      supportedMimeTypes:
        - "application/pdf"
        - "text/plain"
        - "text/markdown"
        - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        - "text/csv"
        - "application/json"


    # If you use a named custom provider (e.g., 'Open Source'), add it here too with the same list.
# MCP Servers Configuration
mcpServers:
#   # Your localhost MCP server with API key authentication
  Landbouw & Natuur:
    type: streamable-http
    url: http://localhost:3434/mcp
    headers:
      Authorization: "Bearer ${GKN_MCP_KEY}"
    timeout: 60000
    chatMenu: true  # Show in chat dropdown (set to false to only use with agents)
    # Custom instructions provided here (overrides server-provided instructions)
    serverInstructions: |
      When using the gkn_search tool, synthesize the results into a clear, comprehensive answer in the language of the question.
      
      **CITE SEARCH RESULTS:**
      Use the EXACT anchor markers provided in the search results. The results include citation markers like \ue202turn0file0.
      Copy these markers into your response immediately after statements derived from that source:
      - Single source: "Veenweidegebieden zijn weidegebieden met een hoge waterstand \ue202turn0file1."
      - Multiple sources: "Dit wordt ondersteund door meerdere studies \ue200\ue202turn0file0\ue202turn0file1\ue201."
      
      **Critical rules:**
      - Copy the \ue202turn0file{number} markers EXACTLY as shown in the search results
      - Place markers immediately after sentences (with a space before)
      - Mention the source title/filename in your text before the citation marker
      - Do NOT use brackets 【】, markdown links, or footnotes
      
      Synthesize information naturally while preserving these citation markers.
    
  # NEO NL:
  #   type: streamable-http
  #   url: http://host.docker.internal:3435/mcp
  #   headers:
  #     Authorization: Bearer ${NEONL_MCP_KEY}
  #   timeout: 60000
  #   serverInstructions: true
  #   chatMenu: true

  # Example additional MCP servers (commented out)
  # filesystem:
  #   type: stdio
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-filesystem"
  #     - /home/user/LibreChat/
  #   iconPath: /home/user/LibreChat/client/public/assets/logo.svg
  # 
  # puppeteer:
  #   type: stdio
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-puppeteer"
  #   timeout: 300000  # 5 minutes timeout

# Definition of custom endpoints
endpoints:
  # assistants:
  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates
  #   timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  #   supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   # Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  #   retrievalModels: ["gpt-4-turbo-preview"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]

  custom:
    #   # Mistral AI Example
    # - name: 'Mistral' # Unique name for the endpoint
    #   # For `apiKey` and `baseURL`, you can use environment variables that you define.
    #   # recommended environment variables:
    #   apiKey: '${MISTRAL_API_KEY}'
    #   baseURL: 'https://api.mistral.ai/v1'

    #   # Models configuration
    #   models:
    #     # List of default models to use. At least one value is required.
    #     default: ['mistral-medium-latest']
    #     # Fetch option: Set to true to fetch models from API.
    #     fetch: true # Defaults to false.
    #   # Optional configurations

    #   # Title Conversation setting
    #   titleConvo: true # Set to true to enable title conversation

    #   # Title Method: Choose between "completion" or "functions".
    #   # titleMethod: "completion"  # Defaults to "completion" if omitted.

    #   # Title Model: Specify the model to use for titles.
    #   titleModel: 'mistral-small-latest' # Defaults to "gpt-3.5-turbo" if omitted.

    #   # Summarize setting: Set to true to enable summarization.
    #   # summarize: false

    #   # Summary Model: Specify the model to use if summarization is enabled.
    #   # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.

    #   # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
    #   # forcePrompt: false

    #   # The label displayed for the AI model in messages.
    #   modelDisplayLabel: 'Mistral' # Default is "AI" when not set.

    #   # Add additional parameters to the request. Default params will be overwritten.
    #   # addParams:
    #   # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/

    #   # Drop Default params parameters from the request. See default params in guide linked below.
    #   # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
    #   dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']
      
    - name: 'Open Source'
      apiKey: '${HF_KEY}'
      baseURL: 'https://router.huggingface.co/v1'
      models:
        default:
          - 'openai/gpt-oss-120b:groq'
        fetch: false
      modelDisplayLabel: 'GovAI'
      titleConvo: true
      titleModel: 'openai/gpt-oss-120b:groq'

    - name: 'Nebul'
      apiKey: '${NEBUL_API_KEY}'
      baseURL: 'https://api.chat.nebul.io/v1'
      models:
        default:
          - 'gpt-oss-120b-nim'
          - 'meta-llama/Llama-4-Maverick-17B-128E-Instruct'
          - 'mistralai/Mistral-Small-3.2-24B-Instruct-2506'
          - 'deepseek-ai/DeepSeek-R1'
          - 'Qwen/Qwen3-VL-235B-A22B-Thinking'
          - 'deepseek-ai/DeepSeek-V3.1'
        fetch: true
      modelDisplayLabel: 'Nebul'
      titleConvo: true
      titleModel: 'gpt-oss-120b-nim'
      # addParams:
      #   tool_choice: 'required'

    # - name: 'UbiOps llama'
    #   apiKey: '${UBIOPS_KEY_LLAMA}'
    #   baseURL: 'https://api.intermax.ubiops.com/v2.1/projects/gradient-ds-proxy/openai-compatible/v1'
    #   models:
    #     default:
    #       - 'ubiops-deployment/llama-3-3//llama-3-3'
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'ubiops-deployment/llama-3-3//llama-3-3'
    #   addParams:
    #     tool_choice: 'required'

    # - name: 'UbiOps GPT'
    #   apiKey: '${UBIOPS_KEY_GPT}'
    #   baseURL: 'https://api.ubiops.com/v2.1/projects/gen-ai/openai-compatible/v1'
    #   models:
    #     default:
    #       - 'ubiops-deployment/gpt-oss//openai/gpt-oss-120b'
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'ubiops-deployment/gpt-oss//openai/gpt-oss-120b'


    # Together AI
    # - name: 'Local'
    #   apiKey: '${TOGETHER_API_KEY}'
    #   baseURL: 'https://api.together.xyz/v1'
    #   models:
    #     default:
    #       - 'Qwen/Qwen3-235B-A22B-Thinking-2507'           # Qwen
    #       - 'deepseek-ai/deepseek-llm-67b-chat'            # DeepSeek
    #       - 'mistralai/Mixtral-8x22B-Instruct-v0.1'        # Mistral
    #       - 'meta-llama/Llama-3-70b-chat-hf'               # Llama 70B
    #       - 'meta-llama/Llama-3-8b-chat-hf'                # Llama 8B
    #       - 'meta-llama/Llama-4-Scout-17B-16E-Instruct'    # Llama 4 Scout 17B 16E
    #       - 'openai/gpt-oss-20b'
    #       - 'openai/gpt-oss-120b'
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'meta-llama/Llama-3-8b-chat-hf'
    #   modelDisplayLabel: 'Local model'

    # UbiOps Example
    # - name: 'UbiOps'
    #   apiKey: '${UBIOPS_API_KEY}'
    #   baseURL: 'https://api.intermax.ubiops.com/v2.1/projects/gradient-ds-proxy/openai-compatible/v1'
    #   models:
    #     default: ['ubiops-deployment/llama-3-3//llama-3-3']
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'ubiops-deployment/llama-3-3//llama-3-3'
    #   iconURL: 'https://scaleway.com/cdn-cgi/image/width=384/https://www-mkt-uploads.s3.fr-par.scw.cloud/2016838564eb_Logo_2_png_969dd089d4.png'
    #   modelDisplayLabel: 'UbiOps'
    #   # Drop parameters that might not be supported
    #   dropParams: ['stop', 'frequency_penalty', 'presence_penalty', 'user', 'logit_bias', 'logprobs', 'top_logprobs', 'n', 'seed', 'response_format']

    # Groq Example
    # - name: 'groq'
    #   apiKey: '${GROQ_API_KEY}'
    #   baseURL: 'https://api.groq.com/openai/v1/'
    #   models:
    #     default:
    #       [
    #         'llama3-70b-8192',
    #         'llama3-8b-8192',
    #         'llama2-70b-4096',
    #         'mixtral-8x7b-32768',
    #         'gemma-7b-it',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'mixtral-8x7b-32768'
    #   modelDisplayLabel: 'groq'

    # # OpenRouter Example
    # - name: 'OpenRouter'
    #   # For `apiKey` and `
  agents:
  #   # (optional) Default recursion depth for agents, defaults to 25
  #   recursionLimit: 50
  #   # (optional) Max recursion depth for agents, defaults to 25
  #   maxRecursionLimit: 100
  #   # (optional) Disable the builder interface for agents
    disableBuilder: false
  #   # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
    capabilities: ["file_search", "web_search", "tools", "chain"]


includedTools:
  - __none__

webSearch:
  searchProvider: "serper"
  scraperType: "firecrawl"
  # searxngInstanceUrl: "${SEARXNG_INSTANCE_URL}"
  # searxngApiKey: "${SEARXNG_API_KEY}"
  # firecrawlApiUrl: "${FIRECRAWL_API_URL}"
  firecrawlApiKey: "${FIRECRAWL_API_KEY}"
    
  # Scraper timeout configuration (in milliseconds)
  scraperTimeout: 30000       # Increased timeout for better reliability
  topResults: 3
  numResults: 3
  # Firecrawl optimization options
  firecrawlOptions:
    timeout: 30000            # Increased timeout to match scraperTimeout
    waitFor: 2000
    blockAds: true
    onlyMainContent: true
    removeBase64Images: true

  safeSearch: 1